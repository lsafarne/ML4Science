{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Overview</h3>\n",
        "<p>The objective of this notebook is to utilize Pytorch framework to train an auto-encoder that can learn representations based on three image channels (ECAL, HCAL, and Tracks) for images in the Quark/Gluon jet events dataset.</p>\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import transforms\n",
        "import h5py\n",
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from torch.utils.data import DataLoader\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: torch in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (1.12.0)\r\nRequirement already satisfied: typing-extensions in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from torch) (4.4.0)\r\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1680508972600
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quark_Gluon_Dataset is a custom dataset class that is derived from the torch.utils.data.Dataset class in PyTorch.\n",
        "\n",
        "This class is used to define a dataset that contains images from Quark/Gluon jet events. \n",
        "\n",
        "The input images are normalized based on their mean and standard deviation. Normalization ensures that the model is less sensitive to pixel value variations, which helps prevent numerical instabilities and allows the optimizer to converge more quickly.\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Quark_Gluon_Dataset(Dataset):\n",
        "    def __init__(self, data_size, start):\n",
        "        with h5py.File('data/quark-gluon_data-set_n139306.hdf5', 'r') as f:\n",
        "            print(f.keys())\n",
        "            self.data_size = data_size\n",
        "            self.x_jets_original = f['X_jets'][start:data_size]\n",
        "            self.x_jet_data = self.normalize_img()\n",
        "            self.transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "\n",
        "\n",
        "            # Read the data from the dataset into a numpy array\n",
        "        f.close()\n",
        "        del f\n",
        "\n",
        "    def normalize_img(self):\n",
        "        res = []\n",
        "        counter = 0\n",
        "        for x_jet in self.x_jets_original:\n",
        "            counter+=1\n",
        "\n",
        "            mean = np.mean(x_jet, axis=(0, 1))\n",
        "            std = np.std(x_jet, axis=(0, 1))\n",
        "            x_jet = (x_jet - mean) / std\n",
        "            # plt.imshow(x_jet)\n",
        "            # plt.show()\n",
        "            res.append(x_jet)\n",
        "\n",
        "        return res\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_jet_data)\n",
        "\n",
        "    def __getitem__(self, indx):\n",
        "        img = self.x_jet_data[indx]\n",
        "        img = self.transform(img)\n",
        "        return img\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1680508972715
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoencoder is a class that defines an autoencoder neural network architecture."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=1, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1680508972842
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cell, first, a PyTorch autoencoder model is trained on the Quark/Gluon jet events dataset. Then,the trained model is used to generate reconstructed images for a subset of the testing data. The original and reconstructed images are visualized side by side for comparison"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_size = 900\n",
        "\n",
        "start=0\n",
        "\n",
        "\n",
        "q_g_train_data = Quark_Gluon_Dataset(data_size,start)\n",
        "\n",
        "\n",
        "# dropout_prob = 0.2\n",
        "# model = Autoencoder(dropout_prob)\n",
        "\n",
        "model = Autoencoder()\n",
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "n_epochs = 20\n",
        "learning_rate =0.01\n",
        "\n",
        "train_loader = DataLoader(q_g_train_data, batch_size= 32, shuffle=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.MSELoss()\n",
        "loss_list = []\n",
        "model.train()\n",
        "for epoch in range(n_epochs):\n",
        "    for x_jet in train_loader:\n",
        "        x_jet = x_jet.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x_jet)\n",
        "        loss = criterion(output,x_jet)\n",
        "        loss_list.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "plt.plot(loss_list)\n",
        "plt.show()\n",
        "model.to('cpu')\n",
        "model.eval()\n",
        "q_g_test_data = Quark_Gluon_Dataset(data_size+100,data_size)\n",
        "\n",
        "for i in range(100):\n",
        "    x_jet = q_g_test_data[i]\n",
        "    #x_jet = x_jet.to('cpu')\n",
        "    output = model(x_jet.unsqueeze(0))\n",
        "    print('test')\n",
        "\n",
        "    # Create a figure with two subplots\n",
        "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n",
        "\n",
        "    # Display the first image in the first subplot\n",
        "    ax1.imshow(x_jet.detach().permute((2, 1, 0)))\n",
        "    ax1.set_title(\"Original x_jet\")\n",
        "\n",
        "    # Display the second image in the second subplot\n",
        "    ax2.imshow(output.squeeze(0).detach().permute((2, 1, 0)))\n",
        "    ax2.set_title(\"Generated x_jet\")\n",
        "\n",
        "    plt.savefig('results/img'+str(i)+'.png')\n",
        "\n",
        "    # Show the plot\n",
        "    if i < 5:\n",
        "        plt.show()\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1680509308616
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
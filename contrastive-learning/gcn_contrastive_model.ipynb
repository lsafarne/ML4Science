{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "<h3>Overview</h3>\n",
    "<p>This notebook aims to build a model to classify quark and gluon jet events using Graph Neural Networks (GNNs).</p>\n",
    "<p>The quark and gluon jet events are represented as 125x125 images with three channels (ECAL, HCAL, and Tracks). These images are first converted into graphs. A GNN model is then constructed to perform graph-level classification.</p>\n",
    "<p>The network consists of two parts: the first part learns graph representations using contrastive learning, while the second part is a classifier that classifies events based on the representations learned in the first part.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1680593385845
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#%pip install torch_geometric\n",
    "#%pip install networkx\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import transforms\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import networkx as nx\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv, TopKPooling, SAGEConv, SAGPooling, global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "<h3>Data Preparation</h3>\n",
    "<p>In the preprocessing phase, images are converted to graph representations by first considering only non-zero pixels. Then the k-nearest neighbors algorithm is applied to determine edges between the nodes.</p>\n",
    "<p>Each node in the graph corresponds to a non-zero pixel in the image. Every node is assigned five features: x-coordinate, y-coordinate, ECAL, HCAL, and Tracks.</p>\n",
    "<p>Quark_Gluon_Dataset is a custom dataset class that is derived from the torch.utils.data.Dataset class in PyTorch.\n",
    "\n",
    "This class is used to define a dataset that contains images from Quark/Gluon jet events. \n",
    "\n",
    "The input images are normalized based on their mean and standard deviation. Normalization ensures that the model is less sensitive to pixel value variations, which helps prevent numerical instabilities and allows the optimizer to converge more quickly.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1680593385994
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "class Quark_Gluon_Dataset_v2(Dataset):\n",
    "    def __init__(self, start,train_data_size):\n",
    "        with h5py.File('data/quark-gluon_data-set_n139306.hdf5', 'r') as f:\n",
    "            print(f.keys())\n",
    "            self.X_jets_data = f['X_jets'][start:train_data_size]\n",
    "            self.y_data = f['y'][start:train_data_size]\n",
    "            self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "            self.graphs, self.augmented_graphs, self.labels = self.process_data()\n",
    "\n",
    "        f.close()\n",
    "        del f\n",
    "\n",
    "    def create_graph_data_v3(self, x_jet, x_jet_normalized, y):\n",
    "        none_zero_point_cloud = []\n",
    "        graph = []\n",
    "        for i in range(len(x_jet[0])):\n",
    "            for j in range(len(x_jet[0][i])):\n",
    "                if x_jet[0][i][j] != 0 or x_jet[1][i][j] != 0 or x_jet[2][i][j] != 0:\n",
    "                    none_zero_point_cloud.append(\n",
    "                        [i, j, x_jet_normalized[i][j][0], x_jet_normalized[i][j][1], x_jet_normalized[i][j][2]])\n",
    "\n",
    "        # Compute the k-NN graph using the point cloud\n",
    "        xy_coordinates = [x[:2] for x in none_zero_point_cloud]\n",
    "        # nbrs = NearestNeighbors(radius=5, algorithm='ball_tree').fit(xy_coordinates)\n",
    "        # distances, indices = nbrs.radius_neighbors(xy_coordinates)\n",
    "        nbrs = NearestNeighbors(n_neighbors=10, algorithm='ball_tree').fit(none_zero_point_cloud)\n",
    "        distances, indices = nbrs.kneighbors(none_zero_point_cloud)\n",
    "\n",
    "        edges = []\n",
    "        for i, node in enumerate(indices):\n",
    "            for j, neigbour in enumerate(node):\n",
    "                if i != j:\n",
    "                    edges.append([i, j, distances[i][j]])\n",
    "\n",
    "        x = torch.tensor(none_zero_point_cloud, dtype=torch.float)\n",
    "        edge_index = torch.tensor([x[:2] for x in edges], dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor([x[2] for x in edges], dtype=torch.float)\n",
    "        y = torch.tensor(int(y), dtype=torch.long)\n",
    "        data = Data(x=x, edge_index=edge_index, y=y)\n",
    "        return data, edges    \n",
    "\n",
    "    def get_augment_graph(self, graph, edges, remove_percent):\n",
    "        augment_edges = edges.copy()\n",
    "        \n",
    "        max_nodes = int(len(augment_edges) * remove_percent)\n",
    "        if max_nodes > 1:\n",
    "            num_nodes_to_remove = random.randrange(1, max_nodes)\n",
    "\n",
    "            for i in range(num_nodes_to_remove):\n",
    "                if len(augment_edges)>0:\n",
    "                    index = random.randrange(0, len(augment_edges))\n",
    "                    del(augment_edges[index])\n",
    "\n",
    "        edge_index = torch.tensor([x[:2] for x in augment_edges], dtype=torch.long).t().contiguous()\n",
    "\n",
    "        return Data(x=graph.x, edge_index=edge_index)\n",
    "\n",
    "    def process_data(self):\n",
    "        graphs = []\n",
    "        augmented_graphs = []\n",
    "        labels = []\n",
    "        counter = 0\n",
    "        for x_jet, y in zip(self.X_jets_data, self.y_data):\n",
    "            counter+=1\n",
    "            mean = np.mean(x_jet, axis=(0, 1))\n",
    "            std = np.std(x_jet, axis=(0, 1))\n",
    "            x_jet_normalized = (x_jet - mean) / std\n",
    "            x_jet_tensor = self.transform(x_jet)\n",
    "            x_jet_data, edges = self.create_graph_data_v3(x_jet_tensor,x_jet_normalized ,y)\n",
    "\n",
    "            if len(edges) < 10:\n",
    "                print(\"graph with a few edges\")\n",
    "                continue\n",
    "\n",
    "            x_jet_augment_data = self.get_augment_graph(x_jet_data, edges, 0.001)\n",
    "\n",
    "            y = torch.tensor(int(y), dtype=torch.long)\n",
    "\n",
    "            graphs.append(x_jet_data)\n",
    "            augmented_graphs.append(x_jet_augment_data)\n",
    "            labels.append(y)\n",
    "\n",
    "        return graphs, augmented_graphs, labels\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "\n",
    "        return self.graphs[index], self.augmented_graphs[index], self.labels[index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Contrastive Learning Network Architecture</h3>\n",
    "<p>This neural network atchitecture consists of two parts. The first part is a Graph Neural Network that is based on the contrastive learning paradigm and aims to learn graph embeddings. The second part is a classifier that classifies jet events based the learned embeddings from the first one. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1680593386169
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "class GraphContrastiveNetDeeperSageBatch(nn.Module):\n",
    "    def __init__(self, feat_dim, hidden_dim, emb_dim, num_classes):\n",
    "        super(GraphContrastiveNetDeeperSageBatch, self).__init__()\n",
    "        \n",
    "        self.sage1 = SAGEConv(feat_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.pool1 = TopKPooling(hidden_dim, ratio=0.8)\n",
    "        self.sage2 = SAGEConv(hidden_dim, emb_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(emb_dim)\n",
    "        self.pool2 = TopKPooling(emb_dim, ratio=0.8)\n",
    "\n",
    "        #self.fc = nn.Linear(emb_dim, num_classes)\n",
    "        # Deeper classifier\n",
    "        # self.classifier_hidden1 = nn.Linear(emb_dim, emb_dim // 2)\n",
    "        # self.classifier_hidden2 = nn.Linear(emb_dim // 2, emb_dim // 4)\n",
    "        # self.classifier_output = nn.Linear(emb_dim // 4, num_classes)\n",
    "        self.classifier_hidden1 = nn.Linear(emb_dim, emb_dim)\n",
    "        self.classifier_hidden2 = nn.Linear(emb_dim , emb_dim//2)\n",
    "        self.classifier_output = nn.Linear(emb_dim//2 , num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        # x = x.to(self.device)\n",
    "        # edge_index = edge_index.to(self.device)\n",
    "        # batch = batch.to(self.device)\n",
    "        x = self.sage1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x = self.sage2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "\n",
    "        #return x, batch\n",
    "        return x\n",
    "\n",
    "    def classify(self,x):\n",
    "        x = F.relu(self.classifier_hidden1(x))\n",
    "        x = F.relu(self.classifier_hidden2(x))\n",
    "        x = self.classifier_output(x)\n",
    "        return x\n",
    "\n",
    "    def pool(self, x, batch):\n",
    "        return global_mean_pool(x, batch)\n",
    "\n",
    "\n",
    "# Define the contrastive loss function\n",
    "class InfoNCELoss(nn.Module):\n",
    "    def __init__(self, temperature):\n",
    "        super(InfoNCELoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        # Compute positive pair similarity\n",
    "        sim_pos = torch.exp(torch.sum(z_i * z_j, dim=1) / self.temperature)\n",
    "\n",
    "        # Compute negative pair similarity\n",
    "        sim_neg = torch.mm(z_i, torch.transpose(z_j, 0, 1))\n",
    "        sim_neg = torch.sum(torch.exp(sim_neg / self.temperature), dim=1)\n",
    "\n",
    "        # Compute InfoNCE loss\n",
    "        loss = -torch.log(sim_pos / (sim_pos + sim_neg))\n",
    "        return loss.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training</h3>\n",
    "<p>A GNN model is trained over 1000 samples. Please note that the dataset contains almost 13000 samples. However, due to limited computational power, I only considered a subset of samples for training. </p>\n",
    "<p>Based on the contrastive loss values, the contrastive learning part is learninng. However, it seems the classifier is still struggling with this setting since the classifier loss is not decresing very much. I believe with more number samples and epochs and also after the contrastive part reachs to the point that it outputs more meaningful embeddings, the classifier will start to improve.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1680594078508
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['X_jets', 'm0', 'pt', 'y']>\n",
      "Epoch: 1, Contrastive Loss: 1.2893807888031006, Classification Loss: 0.6693838834762573, Total Loss: 1.958764672279358\n",
      "Epoch: 2, Contrastive Loss: 1.3495559692382812, Classification Loss: 0.6849379539489746, Total Loss: 2.034493923187256\n",
      "Epoch: 3, Contrastive Loss: 1.14620041847229, Classification Loss: 0.7334892749786377, Total Loss: 1.8796896934509277\n",
      "Epoch: 4, Contrastive Loss: 0.8165686130523682, Classification Loss: 0.6605863571166992, Total Loss: 1.4771549701690674\n",
      "Epoch: 5, Contrastive Loss: 0.8894357681274414, Classification Loss: 0.8033169507980347, Total Loss: 1.692752718925476\n",
      "Epoch: 6, Contrastive Loss: 0.8835732340812683, Classification Loss: 0.7474983334541321, Total Loss: 1.6310715675354004\n",
      "Epoch: 7, Contrastive Loss: 1.0619266033172607, Classification Loss: 0.5989032983779907, Total Loss: 1.6608299016952515\n",
      "Epoch: 8, Contrastive Loss: 0.8440003395080566, Classification Loss: 0.6921497583389282, Total Loss: 1.5361500978469849\n",
      "Epoch: 9, Contrastive Loss: 0.8825105428695679, Classification Loss: 0.664365291595459, Total Loss: 1.5468758344650269\n",
      "Epoch: 10, Contrastive Loss: 0.8772271871566772, Classification Loss: 0.5272125005722046, Total Loss: 1.4044396877288818\n",
      "Epoch: 11, Contrastive Loss: 0.8860961198806763, Classification Loss: 0.8214293718338013, Total Loss: 1.7075254917144775\n",
      "Epoch: 12, Contrastive Loss: 0.748881995677948, Classification Loss: 0.7174610495567322, Total Loss: 1.4663430452346802\n",
      "Epoch: 13, Contrastive Loss: 0.8659192323684692, Classification Loss: 0.8100540637969971, Total Loss: 1.6759732961654663\n",
      "Epoch: 14, Contrastive Loss: 0.7514051198959351, Classification Loss: 0.6385467052459717, Total Loss: 1.3899518251419067\n",
      "Epoch: 15, Contrastive Loss: 0.8946092128753662, Classification Loss: 0.6240554451942444, Total Loss: 1.5186645984649658\n",
      "Epoch: 16, Contrastive Loss: 0.7626626491546631, Classification Loss: 0.5436831712722778, Total Loss: 1.306345820426941\n",
      "Epoch: 17, Contrastive Loss: 0.8561336994171143, Classification Loss: 0.7773759961128235, Total Loss: 1.633509635925293\n",
      "Epoch: 18, Contrastive Loss: 0.9750697612762451, Classification Loss: 0.6223811507225037, Total Loss: 1.5974509716033936\n",
      "Epoch: 19, Contrastive Loss: 0.8882112503051758, Classification Loss: 0.47087278962135315, Total Loss: 1.3590840101242065\n",
      "Epoch: 20, Contrastive Loss: 0.805793046951294, Classification Loss: 0.5713711380958557, Total Loss: 1.3771641254425049\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['X_jets', 'm0', 'pt', 'y']>\n",
      "Accuracy: 0.5312\n",
      "Accuracy: 0.6250\n",
      "Accuracy: 0.6250\n",
      "Accuracy: 0.6719\n",
      "Accuracy: 0.6500\n",
      "Accuracy: 0.6458\n",
      "Accuracy: 0.6518\n",
      "Accuracy: 0.6484\n",
      "Accuracy: 0.6354\n",
      "Accuracy: 0.6375\n",
      "Accuracy: 0.6392\n",
      "Accuracy: 0.6380\n",
      "Accuracy: 0.6466\n",
      "Accuracy: 0.6540\n",
      "Accuracy: 0.6562\n",
      "Accuracy: 0.6543\n",
      "Accuracy: 0.6618\n",
      "Accuracy: 0.6562\n",
      "Accuracy: 0.6546\n",
      "Accuracy: 0.6578\n",
      "Accuracy: 0.6592\n",
      "Accuracy: 0.6619\n",
      "Accuracy: 0.6522\n",
      "Accuracy: 0.6523\n",
      "Accuracy: 0.6550\n",
      "Accuracy: 0.6562\n",
      "Accuracy: 0.6539\n",
      "Accuracy: 0.6562\n",
      "Accuracy: 0.6541\n",
      "Accuracy: 0.6542\n",
      "Accuracy: 0.6603\n",
      "Accuracy: 0.6610\n"
     ]
    }
   ],
   "source": [
    "train_data_size = 1000\n",
    "start = 0\n",
    "\n",
    "dataset = Quark_Gluon_Dataset_v2(start,train_data_size)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "feat_dim = 5\n",
    "hidden_dim = 128\n",
    "emb_dim = 64\n",
    "lr = 0.001\n",
    "num_epochs = 20\n",
    "num_classes = 2\n",
    "tempurture = 0.8\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "loss_list = []\n",
    "model = GraphContrastiveNetDeeperSageBatch(feat_dim, hidden_dim, emb_dim, num_classes)\n",
    "model.to(device)\n",
    "model.train()\n",
    "classifier_criterion = nn.CrossEntropyLoss()\n",
    "contrastive_criterion = InfoNCELoss(tempurture)\n",
    "contrastive_criterion.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    counter = 0\n",
    "    batch_loss = 0\n",
    "    for pos_graphs, neg_graphs, labels in dataloader:\n",
    "        counter+=1\n",
    "        labels = labels.to(device)\n",
    "        x_pos, edge_index_pos, batch_pos = pos_graphs.x, pos_graphs.edge_index, pos_graphs.batch\n",
    "        x_pos = x_pos.to(device)\n",
    "        edge_index_pos = edge_index_pos.to(device)\n",
    "        batch_pos = batch_pos.to(device)\n",
    "\n",
    "        x_neg, edge_index_neg, batch_neg = neg_graphs.x, neg_graphs.edge_index, neg_graphs.batch\n",
    "        x_neg = x_neg.to(device)\n",
    "        edge_index_neg = edge_index_neg.to(device)\n",
    "        batch_neg = batch_neg.to(device)\n",
    "\n",
    "        z_i = model(x_pos, edge_index_pos, batch_pos)\n",
    "        z_j = model(x_neg, edge_index_neg, batch_neg)\n",
    "\n",
    "        contrastive_loss = contrastive_criterion(z_i,z_j)\n",
    "        logits = model.classify(z_i)\n",
    "        optimizer.zero_grad()\n",
    "        classification_loss = classifier_criterion(logits,labels)\n",
    "        loss = contrastive_loss + classification_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss += loss.item()\n",
    "\n",
    "    loss_list.append(batch_loss/counter)\n",
    "    print(\n",
    "        f\"Epoch: {epoch + 1}, Contrastive Loss: {contrastive_loss.item()}, Classification Loss: {classification_loss.item()}, Total Loss: {loss.item()}\")\n",
    "plt.plot(loss_list)\n",
    "plt.show()\n",
    "model.to('cpu')\n",
    "model.eval()\n",
    "test_size = 100\n",
    "dataset_test = Quark_Gluon_Dataset_v2(train_data_size,train_data_size+test_size)\n",
    "testloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    for pos_data, neg_data, labels in testloader:\n",
    "        x_pos, edge_index_pos, batch_pos = pos_data.x, pos_data.edge_index, pos_data.batch\n",
    "\n",
    "        z_i = model(x_pos, edge_index_pos, batch_pos)\n",
    "        logits = model.classify(z_i)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        num_correct += (preds == labels).sum().item()\n",
    "        num_samples += labels.size(0)\n",
    "\n",
    "        acc = num_correct / num_samples\n",
    "        print(f\"Accuracy: {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml-pt-tf"
  },
  "kernelspec": {
   "display_name": "seq2seqvenv",
   "language": "python",
   "name": "seq2seqvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
